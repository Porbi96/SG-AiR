{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bibliotek\n",
    "import os\n",
    "import librosa\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc=1 Ocena klasyfikatora: 3.67 %\n",
      "mfcc=2 Ocena klasyfikatora: 5.00 %\n",
      "mfcc=3 Ocena klasyfikatora: 6.00 %\n",
      "mfcc=4 Ocena klasyfikatora: 11.00 %\n",
      "mfcc=5 Ocena klasyfikatora: 14.33 %\n",
      "mfcc=6 Ocena klasyfikatora: 14.00 %\n",
      "mfcc=7 Ocena klasyfikatora: 21.67 %\n",
      "mfcc=8 Ocena klasyfikatora: 19.67 %\n",
      "mfcc=9 Ocena klasyfikatora: 22.67 %\n",
      "mfcc=10 Ocena klasyfikatora: 22.33 %\n",
      "mfcc=11 Ocena klasyfikatora: 24.67 %\n",
      "mfcc=12 Ocena klasyfikatora: 26.33 %\n",
      "mfcc=13 Ocena klasyfikatora: 27.33 %\n",
      "mfcc=14 Ocena klasyfikatora: 24.00 %\n",
      "mfcc=15 Ocena klasyfikatora: 27.33 %\n",
      "mfcc=16 Ocena klasyfikatora: 26.67 %\n",
      "mfcc=17 Ocena klasyfikatora: 21.33 %\n",
      "mfcc=18 Ocena klasyfikatora: 32.67 %\n",
      "mfcc=19 Ocena klasyfikatora: 29.67 %\n",
      "mfcc=20 Ocena klasyfikatora: 28.33 %\n",
      "mfcc=21 Ocena klasyfikatora: 30.33 %\n",
      "mfcc=22 Ocena klasyfikatora: 24.00 %\n",
      "mfcc=23 Ocena klasyfikatora: 25.00 %\n",
      "mfcc=24 Ocena klasyfikatora: 28.33 %\n",
      "mfcc=25 Ocena klasyfikatora: 28.33 %\n",
      "mfcc=26 Ocena klasyfikatora: 30.67 %\n",
      "mfcc=27 Ocena klasyfikatora: 25.00 %\n",
      "mfcc=28 Ocena klasyfikatora: 28.33 %\n",
      "mfcc=29 Ocena klasyfikatora: 25.67 %\n",
      "mfcc=30 Ocena klasyfikatora: 28.67 %\n",
      "mfcc=31 Ocena klasyfikatora: 28.67 %\n",
      "mfcc=32 Ocena klasyfikatora: 23.67 %\n",
      "mfcc=33 Ocena klasyfikatora: 30.00 %\n",
      "mfcc=34 Ocena klasyfikatora: 26.00 %\n",
      "mfcc=35 Ocena klasyfikatora: 25.33 %\n",
      "mfcc=36 Ocena klasyfikatora: 25.67 %\n",
      "mfcc=37 Ocena klasyfikatora: 26.00 %\n",
      "mfcc=38 Ocena klasyfikatora: 26.33 %\n",
      "mfcc=39 Ocena klasyfikatora: 30.00 %\n",
      "mfcc=40 Ocena klasyfikatora: 24.33 %\n",
      "mfcc=41 Ocena klasyfikatora: 26.00 %\n",
      "mfcc=42 Ocena klasyfikatora: 25.00 %\n",
      "mfcc=43 Ocena klasyfikatora: 26.67 %\n",
      "mfcc=44 Ocena klasyfikatora: 25.67 %\n",
      "mfcc=45 Ocena klasyfikatora: 25.00 %\n",
      "mfcc=46 Ocena klasyfikatora: 27.67 %\n",
      "mfcc=47 Ocena klasyfikatora: 28.67 %\n",
      "mfcc=48 Ocena klasyfikatora: 23.33 %\n",
      "mfcc=49 Ocena klasyfikatora: 26.00 %\n",
      "mfcc=50 Ocena klasyfikatora: 23.67 %\n",
      "mfcc=51 Ocena klasyfikatora: 23.00 %\n",
      "mfcc=52 Ocena klasyfikatora: 25.33 %\n",
      "mfcc=53 Ocena klasyfikatora: 26.67 %\n",
      "mfcc=54 Ocena klasyfikatora: 21.33 %\n",
      "mfcc=55 Ocena klasyfikatora: 26.33 %\n",
      "mfcc=56 Ocena klasyfikatora: 28.67 %\n",
      "mfcc=57 Ocena klasyfikatora: 26.67 %\n",
      "mfcc=58 Ocena klasyfikatora: 24.33 %\n",
      "mfcc=59 Ocena klasyfikatora: 25.67 %\n",
      "mfcc=60 Ocena klasyfikatora: 23.00 %\n",
      "mfcc=61 Ocena klasyfikatora: 26.33 %\n",
      "mfcc=62 Ocena klasyfikatora: 27.67 %\n",
      "mfcc=63 Ocena klasyfikatora: 27.33 %\n",
      "mfcc=64 Ocena klasyfikatora: 21.67 %\n",
      "mfcc=65 Ocena klasyfikatora: 25.00 %\n",
      "mfcc=66 Ocena klasyfikatora: 24.67 %\n",
      "mfcc=67 Ocena klasyfikatora: 22.00 %\n",
      "mfcc=68 Ocena klasyfikatora: 23.00 %\n",
      "mfcc=69 Ocena klasyfikatora: 22.33 %\n",
      "mfcc=70 Ocena klasyfikatora: 19.67 %\n",
      "mfcc=71 Ocena klasyfikatora: 21.67 %\n",
      "mfcc=72 Ocena klasyfikatora: 18.00 %\n",
      "mfcc=73 Ocena klasyfikatora: 26.00 %\n",
      "mfcc=74 Ocena klasyfikatora: 23.00 %\n",
      "mfcc=75 Ocena klasyfikatora: 23.67 %\n",
      "mfcc=76 Ocena klasyfikatora: 23.00 %\n",
      "mfcc=77 Ocena klasyfikatora: 21.00 %\n",
      "mfcc=78 Ocena klasyfikatora: 18.67 %\n",
      "mfcc=79 Ocena klasyfikatora: 24.00 %\n",
      "mfcc=80 Ocena klasyfikatora: 21.33 %\n",
      "mfcc=81 Ocena klasyfikatora: 26.00 %\n",
      "mfcc=82 Ocena klasyfikatora: 20.67 %\n",
      "mfcc=83 Ocena klasyfikatora: 19.67 %\n",
      "mfcc=84 Ocena klasyfikatora: 22.33 %\n",
      "mfcc=85 Ocena klasyfikatora: 23.33 %\n",
      "mfcc=86 Ocena klasyfikatora: 22.00 %\n",
      "mfcc=87 Ocena klasyfikatora: 24.00 %\n",
      "mfcc=88 Ocena klasyfikatora: 20.67 %\n",
      "mfcc=89 Ocena klasyfikatora: 17.67 %\n",
      "mfcc=90 Ocena klasyfikatora: 24.33 %\n",
      "mfcc=91 Ocena klasyfikatora: 21.67 %\n",
      "mfcc=92 Ocena klasyfikatora: 22.00 %\n",
      "mfcc=93 Ocena klasyfikatora: 23.00 %\n",
      "mfcc=94 Ocena klasyfikatora: 20.33 %\n",
      "mfcc=95 Ocena klasyfikatora: 23.00 %\n",
      "mfcc=96 Ocena klasyfikatora: 22.33 %\n",
      "mfcc=97 Ocena klasyfikatora: 19.33 %\n",
      "mfcc=98 Ocena klasyfikatora: 23.67 %\n",
      "mfcc=99 Ocena klasyfikatora: 20.33 %\n",
      "mfcc=100 Ocena klasyfikatora: 25.67 %\n",
      "best_mfcc = 18; best_quality = 32.666666666666664\n"
     ]
    }
   ],
   "source": [
    "# 2. Wybór danych treningowych i testowych\n",
    "\n",
    "# Zautomatyzowany i losowy sposób to użycie:\n",
    "# \"from sklearn.model_selection import train_test_split\" oraz funkcji \"train_test_split()\"\n",
    "\n",
    "best_mfcc = 0\n",
    "best_quality = 0\n",
    "for N in range(1,101):\n",
    "    # wczytanie danych\n",
    "    database = open(f'classes/database{N}.pkl', 'rb')\n",
    "    classes, samples, labels = pickle.load(database)\n",
    "    database.close()\n",
    "\n",
    "    # wybierzmy 10 pierwszych próbek z każdej klasy jako uczące\n",
    "    # oraz kolejne 2 z każdej klasy jako testowe\n",
    "    # uwaga! train_size + test_size NIE może przekroczyć class_size (poprzedni punkt)\n",
    "    train_size = 40\n",
    "    test_size = 10\n",
    "    train_samples = []\n",
    "    train_labels = []\n",
    "    test_samples = []\n",
    "    test_labels = []\n",
    "\n",
    "    max_iter = 10000\n",
    "    it = 0\n",
    "    used_idxs = []\n",
    "    for classname in classes:\n",
    "        train_size_index = 0\n",
    "        test_size_index = 0\n",
    "        it = 0\n",
    "        used_idxs = []\n",
    "        \n",
    "        while(train_size_index < train_size):\n",
    "            idx = random.randint(0, len(labels)-1)\n",
    "            it += 1\n",
    "            if labels[idx] == classname and (idx not in used_idxs):\n",
    "                train_samples.append(samples[idx])\n",
    "                train_labels.append(labels[idx])\n",
    "                train_size_index += 1\n",
    "                used_idxs.append(idx)\n",
    "            if it > max_iter:\n",
    "                break\n",
    "        \n",
    "        while(test_size_index < test_size):\n",
    "            idx = random.randint(0, len(labels)-1)\n",
    "            it += 1\n",
    "            if labels[idx] == classname and (idx not in used_idxs):\n",
    "                test_samples.append(samples[idx])\n",
    "                test_labels.append(labels[idx])\n",
    "                test_size_index += 1\n",
    "                used_idxs.append(idx)\n",
    "            if it > max_iter:\n",
    "                break\n",
    "        \n",
    "#         for i in range(len(labels)):\n",
    "#             if labels[i] == classname and train_size_index < train_size:\n",
    "#                 train_samples.append(samples[i])\n",
    "#                 train_labels.append(labels[i])\n",
    "#                 train_size_index += 1\n",
    "#             elif labels[i] == classname and test_size_index < test_size:\n",
    "#                 test_samples.append(samples[i])\n",
    "#                 test_labels.append(labels[i])\n",
    "#                 test_size_index += 1\n",
    "#             if train_size_index == train_size and test_size_index == test_size:\n",
    "#                 break\n",
    "\n",
    "    # proszę sprawdzić, czy dane zostały wybrane prawidłowo\n",
    "\n",
    "\n",
    "    # 3. Uczenie klasyfikatora danymi treningowymi\n",
    "\n",
    "    # Lista klasyfikatorów: https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/\n",
    "    # Prosty tutorial: https://www.digitalocean.com/community/tutorials/how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn\n",
    "\n",
    "    # skalowanie/normalizacja danych\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_samples)\n",
    "    train_samples = scaler.transform(train_samples)\n",
    "    test_samples = scaler.transform(test_samples)\n",
    "\n",
    "    # uczenie\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    C = 1.0\n",
    "    classifier = LogisticRegression(C = C, max_iter=10000)\n",
    "    classifier.fit(train_samples, train_labels)\n",
    "\n",
    "\n",
    "    # 4. Klasyfikacja nieznanych próbek\n",
    "    predicted_labels = classifier.predict(test_samples)\n",
    "\n",
    "    # zobaczmy wynik - zakomentować dla dużych zbiorów\n",
    "    # print(test_labels)\n",
    "    # print(predicted_labels)\n",
    "\n",
    "\n",
    "    # 5. Ocena klasyfikatora\n",
    "    # print(test_labels == predicted_labels)\n",
    "    quality = numpy.sum(test_labels == predicted_labels) / len(test_labels) * 100;\n",
    "    print(f'mfcc={N} Ocena klasyfikatora: %.2f %%' % quality)\n",
    "    if (quality > best_quality):\n",
    "        best_mfcc = N\n",
    "        best_quality = quality\n",
    "\n",
    "print(f\"best_mfcc = {best_mfcc}; best_quality = {best_quality}\")\n",
    "n_mfcc_optimal = best_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size=1 Ocena klasyfikatora: 5.59 %\n",
      "train_size=2 Ocena klasyfikatora: 9.21 %\n",
      "train_size=3 Ocena klasyfikatora: 16.17 %\n",
      "train_size=4 Ocena klasyfikatora: 12.25 %\n",
      "train_size=5 Ocena klasyfikatora: 10.30 %\n",
      "train_size=6 Ocena klasyfikatora: 15.67 %\n",
      "train_size=7 Ocena klasyfikatora: 20.67 %\n",
      "train_size=8 Ocena klasyfikatora: 19.00 %\n",
      "train_size=9 Ocena klasyfikatora: 21.67 %\n",
      "train_size=10 Ocena klasyfikatora: 17.33 %\n",
      "train_size=11 Ocena klasyfikatora: 15.33 %\n",
      "train_size=12 Ocena klasyfikatora: 22.00 %\n",
      "train_size=13 Ocena klasyfikatora: 22.00 %\n",
      "train_size=14 Ocena klasyfikatora: 26.00 %\n",
      "train_size=15 Ocena klasyfikatora: 18.00 %\n",
      "train_size=16 Ocena klasyfikatora: 21.00 %\n",
      "train_size=17 Ocena klasyfikatora: 22.33 %\n",
      "train_size=18 Ocena klasyfikatora: 22.67 %\n",
      "train_size=19 Ocena klasyfikatora: 21.67 %\n",
      "train_size=20 Ocena klasyfikatora: 24.33 %\n",
      "train_size=21 Ocena klasyfikatora: 23.33 %\n",
      "train_size=22 Ocena klasyfikatora: 20.67 %\n",
      "train_size=23 Ocena klasyfikatora: 23.00 %\n",
      "train_size=24 Ocena klasyfikatora: 26.33 %\n",
      "train_size=25 Ocena klasyfikatora: 24.33 %\n",
      "train_size=26 Ocena klasyfikatora: 24.67 %\n",
      "train_size=27 Ocena klasyfikatora: 26.00 %\n",
      "train_size=28 Ocena klasyfikatora: 24.00 %\n",
      "train_size=29 Ocena klasyfikatora: 23.00 %\n",
      "train_size=30 Ocena klasyfikatora: 26.67 %\n",
      "train_size=31 Ocena klasyfikatora: 21.67 %\n",
      "train_size=32 Ocena klasyfikatora: 24.67 %\n",
      "train_size=33 Ocena klasyfikatora: 28.00 %\n",
      "train_size=34 Ocena klasyfikatora: 25.33 %\n",
      "train_size=35 Ocena klasyfikatora: 23.33 %\n",
      "train_size=36 Ocena klasyfikatora: 27.67 %\n",
      "train_size=37 Ocena klasyfikatora: 27.33 %\n",
      "train_size=38 Ocena klasyfikatora: 27.00 %\n",
      "train_size=39 Ocena klasyfikatora: 26.33 %\n",
      "train_size=40 Ocena klasyfikatora: 26.67 %\n",
      "train_size=41 Ocena klasyfikatora: 27.67 %\n",
      "train_size=42 Ocena klasyfikatora: 28.33 %\n",
      "train_size=43 Ocena klasyfikatora: 29.00 %\n",
      "train_size=44 Ocena klasyfikatora: 30.00 %\n",
      "train_size=45 Ocena klasyfikatora: 29.33 %\n",
      "train_size=46 Ocena klasyfikatora: 28.00 %\n",
      "train_size=47 Ocena klasyfikatora: 25.67 %\n",
      "train_size=48 Ocena klasyfikatora: 25.33 %\n",
      "train_size=49 Ocena klasyfikatora: 30.00 %\n",
      "train_size=50 Ocena klasyfikatora: 28.33 %\n",
      "train_size=51 Ocena klasyfikatora: 24.67 %\n",
      "train_size=52 Ocena klasyfikatora: 28.00 %\n",
      "train_size=53 Ocena klasyfikatora: 27.67 %\n",
      "train_size=54 Ocena klasyfikatora: 28.00 %\n",
      "train_size=55 Ocena klasyfikatora: 27.00 %\n",
      "train_size=56 Ocena klasyfikatora: 30.67 %\n",
      "train_size=57 Ocena klasyfikatora: 27.33 %\n",
      "train_size=58 Ocena klasyfikatora: 26.67 %\n",
      "train_size=59 Ocena klasyfikatora: 30.00 %\n",
      "train_size=60 Ocena klasyfikatora: 28.33 %\n",
      "train_size=61 Ocena klasyfikatora: 27.67 %\n",
      "train_size=62 Ocena klasyfikatora: 26.67 %\n",
      "train_size=63 Ocena klasyfikatora: 31.00 %\n",
      "train_size=64 Ocena klasyfikatora: 31.00 %\n",
      "train_size=65 Ocena klasyfikatora: 31.67 %\n",
      "train_size=66 Ocena klasyfikatora: 33.33 %\n",
      "train_size=67 Ocena klasyfikatora: 27.33 %\n",
      "train_size=68 Ocena klasyfikatora: 29.00 %\n",
      "train_size=69 Ocena klasyfikatora: 26.67 %\n",
      "train_size=70 Ocena klasyfikatora: 30.33 %\n",
      "train_size=71 Ocena klasyfikatora: 26.33 %\n",
      "train_size=72 Ocena klasyfikatora: 23.33 %\n",
      "train_size=73 Ocena klasyfikatora: 24.00 %\n",
      "train_size=74 Ocena klasyfikatora: 33.00 %\n",
      "train_size=75 Ocena klasyfikatora: 28.67 %\n",
      "train_size=76 Ocena klasyfikatora: 27.67 %\n",
      "train_size=77 Ocena klasyfikatora: 30.67 %\n",
      "train_size=78 Ocena klasyfikatora: 31.33 %\n",
      "train_size=79 Ocena klasyfikatora: 30.00 %\n",
      "train_size=80 Ocena klasyfikatora: 31.67 %\n",
      "train_size=81 Ocena klasyfikatora: 29.33 %\n",
      "train_size=82 Ocena klasyfikatora: 27.67 %\n",
      "train_size=83 Ocena klasyfikatora: 29.67 %\n",
      "train_size=84 Ocena klasyfikatora: 31.67 %\n",
      "train_size=85 Ocena klasyfikatora: 29.33 %\n",
      "train_size=86 Ocena klasyfikatora: 28.33 %\n",
      "train_size=87 Ocena klasyfikatora: 28.00 %\n",
      "train_size=88 Ocena klasyfikatora: 31.67 %\n",
      "train_size=89 Ocena klasyfikatora: 26.67 %\n",
      "train_size=90 Ocena klasyfikatora: 28.00 %\n",
      "best_train_size = 66; best_quality = 33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# 2. Dobór optymalny zbioru testowego\n",
    "\n",
    "# Zautomatyzowany i losowy sposób to użycie:\n",
    "# \"from sklearn.model_selection import train_test_split\" oraz funkcji \"train_test_split()\"\n",
    "\n",
    "best_mfcc = n_mfcc_optimal\n",
    "\n",
    "best_train_size = 0\n",
    "best_quality = 0\n",
    "for N in range(1,91):\n",
    "    # wczytanie danych\n",
    "    database = open(f'classes/database{best_mfcc}.pkl', 'rb')\n",
    "    classes, samples, labels = pickle.load(database)\n",
    "    database.close()\n",
    "\n",
    "    # wybierzmy 10 pierwszych próbek z każdej klasy jako uczące\n",
    "    # oraz kolejne 2 z każdej klasy jako testowe\n",
    "    # uwaga! train_size + test_size NIE może przekroczyć class_size (poprzedni punkt)\n",
    "    train_size = N\n",
    "    test_size = 10\n",
    "    train_samples = []\n",
    "    train_labels = []\n",
    "    test_samples = []\n",
    "    test_labels = []\n",
    "\n",
    "    max_iter = 10000\n",
    "    it = 0\n",
    "    used_idxs = []\n",
    "    for classname in classes:\n",
    "        train_size_index = 0\n",
    "        test_size_index = 0\n",
    "        it = 0\n",
    "        used_idxs = []\n",
    "        \n",
    "        while(train_size_index < train_size):\n",
    "            idx = random.randint(0, len(labels)-1)\n",
    "            it += 1\n",
    "            if labels[idx] == classname and (idx not in used_idxs):\n",
    "                train_samples.append(samples[idx])\n",
    "                train_labels.append(labels[idx])\n",
    "                train_size_index += 1\n",
    "                used_idxs.append(idx)\n",
    "            if it > max_iter:\n",
    "                break\n",
    "        \n",
    "        while(test_size_index < test_size):\n",
    "            idx = random.randint(0, len(labels)-1)\n",
    "            it += 1\n",
    "            if labels[idx] == classname and (idx not in used_idxs):\n",
    "                test_samples.append(samples[idx])\n",
    "                test_labels.append(labels[idx])\n",
    "                test_size_index += 1\n",
    "                used_idxs.append(idx)\n",
    "            if it > max_iter:\n",
    "                break\n",
    "        \n",
    "#         for i in range(len(labels)):\n",
    "#             if labels[i] == classname and train_size_index < train_size:\n",
    "#                 train_samples.append(samples[i])\n",
    "#                 train_labels.append(labels[i])\n",
    "#                 train_size_index += 1\n",
    "#             elif labels[i] == classname and test_size_index < test_size:\n",
    "#                 test_samples.append(samples[i])\n",
    "#                 test_labels.append(labels[i])\n",
    "#                 test_size_index += 1\n",
    "#             if train_size_index == train_size and test_size_index == test_size:\n",
    "#                 break\n",
    "\n",
    "    # proszę sprawdzić, czy dane zostały wybrane prawidłowo\n",
    "\n",
    "\n",
    "    # 3. Uczenie klasyfikatora danymi treningowymi\n",
    "\n",
    "    # Lista klasyfikatorów: https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/\n",
    "    # Prosty tutorial: https://www.digitalocean.com/community/tutorials/how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn\n",
    "\n",
    "    # skalowanie/normalizacja danych\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_samples)\n",
    "    train_samples = scaler.transform(train_samples)\n",
    "    test_samples = scaler.transform(test_samples)\n",
    "\n",
    "    # uczenie\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    C = 1.0\n",
    "    classifier = LogisticRegression(C = C, max_iter=10000)\n",
    "    classifier.fit(train_samples, train_labels)\n",
    "    \n",
    "    # 4. Klasyfikacja nieznanych próbek\n",
    "    predicted_labels = classifier.predict(test_samples)\n",
    "\n",
    "    # zobaczmy wynik - zakomentować dla dużych zbiorów\n",
    "    # print(test_labels)\n",
    "    # print(predicted_labels)\n",
    "\n",
    "\n",
    "    # 5. Ocena klasyfikatora\n",
    "    # print(test_labels == predicted_labels)\n",
    "    quality = numpy.sum(test_labels == predicted_labels) / len(test_labels) * 100;\n",
    "    print(f'train_size={N} Ocena klasyfikatora: %.2f %%' % quality)\n",
    "    if (quality > best_quality):\n",
    "        best_train_size = N\n",
    "        best_quality = quality\n",
    "\n",
    "print(f\"best_train_size = {best_train_size}; best_quality = {best_quality}\")\n",
    "train_size_optimal = best_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1 Ocena klasyfikatora: 32.33 %\n",
      "C=0.2 Ocena klasyfikatora: 23.33 %\n",
      "C=0.30000000000000004 Ocena klasyfikatora: 28.00 %\n",
      "C=0.4 Ocena klasyfikatora: 29.67 %\n",
      "C=0.5 Ocena klasyfikatora: 30.33 %\n",
      "C=0.6000000000000001 Ocena klasyfikatora: 22.33 %\n",
      "C=0.7000000000000001 Ocena klasyfikatora: 26.67 %\n",
      "C=0.8 Ocena klasyfikatora: 25.67 %\n",
      "C=0.9 Ocena klasyfikatora: 30.00 %\n",
      "C=1.0 Ocena klasyfikatora: 29.00 %\n",
      "C=1.1 Ocena klasyfikatora: 27.33 %\n",
      "C=1.2000000000000002 Ocena klasyfikatora: 27.33 %\n",
      "C=1.3 Ocena klasyfikatora: 30.67 %\n",
      "C=1.4000000000000001 Ocena klasyfikatora: 27.33 %\n",
      "C=1.5 Ocena klasyfikatora: 24.33 %\n",
      "C=1.6 Ocena klasyfikatora: 24.00 %\n",
      "C=1.7000000000000002 Ocena klasyfikatora: 28.33 %\n",
      "C=1.8 Ocena klasyfikatora: 24.67 %\n",
      "C=1.9000000000000001 Ocena klasyfikatora: 28.33 %\n",
      "C=2.0 Ocena klasyfikatora: 30.67 %\n",
      "C=2.1 Ocena klasyfikatora: 35.33 %\n",
      "C=2.2 Ocena klasyfikatora: 28.67 %\n",
      "C=2.3000000000000003 Ocena klasyfikatora: 28.00 %\n",
      "C=2.4000000000000004 Ocena klasyfikatora: 28.00 %\n",
      "C=2.5 Ocena klasyfikatora: 28.33 %\n",
      "C=2.6 Ocena klasyfikatora: 28.00 %\n",
      "C=2.7 Ocena klasyfikatora: 30.33 %\n",
      "C=2.8000000000000003 Ocena klasyfikatora: 29.67 %\n",
      "C=2.9000000000000004 Ocena klasyfikatora: 28.33 %\n",
      "C=3.0 Ocena klasyfikatora: 32.33 %\n",
      "best_C = 2.1; best_quality = 35.333333333333336\n"
     ]
    }
   ],
   "source": [
    "# 2. Dobór optymalny parametru C\n",
    "\n",
    "# Zautomatyzowany i losowy sposób to użycie:\n",
    "# \"from sklearn.model_selection import train_test_split\" oraz funkcji \"train_test_split()\"\n",
    "\n",
    "best_mfcc = n_mfcc_optimal\n",
    "best_train_size = train_size_optimal\n",
    "\n",
    "best_C = 0\n",
    "best_quality = 0\n",
    "for N in range(1,31):\n",
    "    # wczytanie danych\n",
    "    database = open(f'classes/database{best_mfcc}.pkl', 'rb')\n",
    "    classes, samples, labels = pickle.load(database)\n",
    "    database.close()\n",
    "\n",
    "    # wybierzmy 10 pierwszych próbek z każdej klasy jako uczące\n",
    "    # oraz kolejne 2 z każdej klasy jako testowe\n",
    "    # uwaga! train_size + test_size NIE może przekroczyć class_size (poprzedni punkt)\n",
    "    train_size = best_train_size\n",
    "    test_size = 10\n",
    "    train_samples = []\n",
    "    train_labels = []\n",
    "    test_samples = []\n",
    "    test_labels = []\n",
    "    \n",
    "    max_iter = 10000\n",
    "    it = 0\n",
    "    used_idxs = []\n",
    "    for classname in classes:\n",
    "        train_size_index = 0\n",
    "        test_size_index = 0\n",
    "        it = 0\n",
    "        used_idxs = []\n",
    "        \n",
    "        while(train_size_index < train_size):\n",
    "            idx = random.randint(0, len(labels)-1)\n",
    "            it += 1\n",
    "            if labels[idx] == classname and (idx not in used_idxs):\n",
    "                train_samples.append(samples[idx])\n",
    "                train_labels.append(labels[idx])\n",
    "                train_size_index += 1\n",
    "                used_idxs.append(idx)\n",
    "            if it > max_iter:\n",
    "                break\n",
    "        \n",
    "        while(test_size_index < test_size):\n",
    "            idx = random.randint(0, len(labels)-1)\n",
    "            it += 1\n",
    "            if labels[idx] == classname and (idx not in used_idxs):\n",
    "                test_samples.append(samples[idx])\n",
    "                test_labels.append(labels[idx])\n",
    "                test_size_index += 1\n",
    "                used_idxs.append(idx)\n",
    "            if it > max_iter:\n",
    "                break\n",
    "        \n",
    "#         for i in range(len(labels)):\n",
    "#             if labels[i] == classname and train_size_index < train_size:\n",
    "#                 train_samples.append(samples[i])\n",
    "#                 train_labels.append(labels[i])\n",
    "#                 train_size_index += 1\n",
    "#             elif labels[i] == classname and test_size_index < test_size:\n",
    "#                 test_samples.append(samples[i])\n",
    "#                 test_labels.append(labels[i])\n",
    "#                 test_size_index += 1\n",
    "#             if train_size_index == train_size and test_size_index == test_size:\n",
    "#                 break\n",
    "\n",
    "    # proszę sprawdzić, czy dane zostały wybrane prawidłowo\n",
    "\n",
    "\n",
    "    # 3. Uczenie klasyfikatora danymi treningowymi\n",
    "\n",
    "    # Lista klasyfikatorów: https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/\n",
    "    # Prosty tutorial: https://www.digitalocean.com/community/tutorials/how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn\n",
    "\n",
    "    # skalowanie/normalizacja danych\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_samples)\n",
    "    train_samples = scaler.transform(train_samples)\n",
    "    test_samples = scaler.transform(test_samples)\n",
    "\n",
    "    # uczenie\n",
    "    # uczenie\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    C = 0.1*N\n",
    "    classifier = LogisticRegression(C = C, max_iter=10000)\n",
    "    classifier.fit(train_samples, train_labels)\n",
    "\n",
    "\n",
    "    # 4. Klasyfikacja nieznanych próbek\n",
    "    predicted_labels = classifier.predict(test_samples)\n",
    "\n",
    "    # zobaczmy wynik - zakomentować dla dużych zbiorów\n",
    "    # print(test_labels)\n",
    "    # print(predicted_labels)\n",
    "\n",
    "\n",
    "    # 5. Ocena klasyfikatora\n",
    "    # print(test_labels == predicted_labels)\n",
    "    quality = numpy.sum(test_labels == predicted_labels) / len(test_labels) * 100;\n",
    "    print(f'C={N*0.1} Ocena klasyfikatora: %.2f %%' % quality)\n",
    "    if (quality > best_quality):\n",
    "        best_C = N*0.1\n",
    "        best_quality = quality\n",
    "\n",
    "print(f\"best_C = {best_C}; best_quality = {best_quality}\")\n",
    "C_optimal = best_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dobrane parametry:\n",
    "# mfcc 18\n",
    "# train size 66\n",
    "# C = 2.1\n",
    "\n",
    "# Finalna wartosc parametru quality: 35.3\n",
    "# Losowy wybor zbioru treningowego i testowego pozwala na osiagniecie lepszych, lecz niepowtarzalnych, rezultatow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sg-venv",
   "language": "python",
   "name": "sg-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
