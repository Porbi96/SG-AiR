{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "three\n",
      "two\n",
      "wow\n",
      "zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_audio_path = '../data/'\n",
    "labels=[\"stop\", \"three\", \"two\", \"wow\", \"zero\"]\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if(len(samples)== 8000) : \n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(all_label)\n",
    "classes= list(le.classes_)\n",
    "\n",
    "y=np_utils.to_categorical(y, num_classes=len(labels))\n",
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7988, 8)           112       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2662, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2662, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2652, 16)          1424      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 884, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 884, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 876, 32)           4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 292, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 292, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 286, 64)           14400     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 95, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 95, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6080)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1556736   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,610,853\n",
      "Trainable params: 33,541\n",
      "Non-trainable params: 1,577,312\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8834 - accuracy: 0.6508\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67698, saving model to tl_best_model_20_2ndSet.hdf5\n",
      "64/64 [==============================] - 15s 238ms/step - loss: 0.8860 - accuracy: 0.6495 - val_loss: 0.8423 - val_accuracy: 0.6770\n",
      "Epoch 2/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8913 - accuracy: 0.6478\n",
      "Epoch 00002: val_accuracy did not improve from 0.67698\n",
      "64/64 [==============================] - 15s 240ms/step - loss: 0.8903 - accuracy: 0.6490 - val_loss: 0.8345 - val_accuracy: 0.6764\n",
      "Epoch 3/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.9011 - accuracy: 0.6508\n",
      "Epoch 00003: val_accuracy improved from 0.67698 to 0.67722, saving model to tl_best_model_20_2ndSet.hdf5\n",
      "64/64 [==============================] - 15s 238ms/step - loss: 0.8993 - accuracy: 0.6514 - val_loss: 0.8353 - val_accuracy: 0.6772\n",
      "Epoch 4/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8832 - accuracy: 0.6473\n",
      "Epoch 00004: val_accuracy did not improve from 0.67722\n",
      "64/64 [==============================] - 15s 239ms/step - loss: 0.8831 - accuracy: 0.6475 - val_loss: 0.8310 - val_accuracy: 0.6771\n",
      "Epoch 5/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8761 - accuracy: 0.6513\n",
      "Epoch 00005: val_accuracy improved from 0.67722 to 0.67759, saving model to tl_best_model_20_2ndSet.hdf5\n",
      "64/64 [==============================] - 17s 267ms/step - loss: 0.8817 - accuracy: 0.6505 - val_loss: 0.8302 - val_accuracy: 0.6776\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8872 - accuracy: 0.6490\n",
      "Epoch 00006: val_accuracy improved from 0.67759 to 0.68029, saving model to tl_best_model_20_2ndSet.hdf5\n",
      "64/64 [==============================] - 16s 257ms/step - loss: 0.8872 - accuracy: 0.6490 - val_loss: 0.8296 - val_accuracy: 0.6803\n",
      "Epoch 7/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8855 - accuracy: 0.6478\n",
      "Epoch 00007: val_accuracy did not improve from 0.68029\n",
      "64/64 [==============================] - 15s 242ms/step - loss: 0.8854 - accuracy: 0.6475 - val_loss: 0.8264 - val_accuracy: 0.6799\n",
      "Epoch 8/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8753 - accuracy: 0.6562\n",
      "Epoch 00008: val_accuracy improved from 0.68029 to 0.68422, saving model to tl_best_model_20_2ndSet.hdf5\n",
      "64/64 [==============================] - 16s 252ms/step - loss: 0.8752 - accuracy: 0.6554 - val_loss: 0.8252 - val_accuracy: 0.6842\n",
      "Epoch 9/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8687 - accuracy: 0.6567\n",
      "Epoch 00009: val_accuracy did not improve from 0.68422\n",
      "64/64 [==============================] - 16s 254ms/step - loss: 0.8658 - accuracy: 0.6578 - val_loss: 0.8251 - val_accuracy: 0.6836\n",
      "Epoch 10/10\n",
      "63/64 [============================>.] - ETA: 0s - loss: 0.8770 - accuracy: 0.6558\n",
      "Epoch 00010: val_accuracy did not improve from 0.68422\n",
      "64/64 [==============================] - 18s 280ms/step - loss: 0.8777 - accuracy: 0.6554 - val_loss: 0.8271 - val_accuracy: 0.6813\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "base_model = load_model('speech_assistant_model.hdf5')\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False;\n",
    "base_model.summary()\n",
    "\n",
    "# model2= Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
    "# # model2.summary()\n",
    "\n",
    "# x = model2.output\n",
    "# x = Dense(len(labels), activation='softmax')(x)\n",
    "\n",
    "# final_model = Model(inputs=model2.input, outputs=x)\n",
    "# final_model.summary()\n",
    "\n",
    "# new_model = Model(inputs=base_model.input, outputs=)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(all_wave),np.array(y),stratify=y,\n",
    "                                            test_size = 0.8,random_state=777,shuffle=True)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
    "mc = ModelCheckpoint('tl_best_model_20_2ndSet.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "final_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = final_model.fit(x_train, y_train, epochs=10, callbacks=[es,mc], batch_size=32, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sg-venv",
   "language": "python",
   "name": "sg-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
